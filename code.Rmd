---
title: "code"
author: "Tim"
date: "2024-06-29"
output: html_document
---

```{r}
#attention check
library(dplyr)
# here is the file list
file_list<- c("Day_10_LVC_Afternoon_Survey_June_28_2024_23_12.csv  Day_3_LVC_Midday_Survey_June_28_2024_22_58.csv",
              "Day_7_LVC_Evening_Survey_June_28_2024_23_08.csv","Day_10_LVC_Evening_Survey_June_28_2024_23_13.csv",
              "Day_4_LVC_Afternoon_Survey_June_28_2024_23_01.csv","Day_7_LVC_Midday_Survey_June_28_2024_23_08.csv",
              "Day_10_LVC_Midday_Survey_June_28_2024_23_13.csv","Day_4_LVC_Evening_Survey_June_28_2024_23_02.csv",
              "Day_8_LVC_Afternoon_Survey_June_28_2024_23_09.csv","Day_1_LVC_Afternoon_Survey_June_28_2024_22_53.csv",
              "Day_4_LVC_Midday_Survey_June_28_2024_23_02.csv","Day_8_LVC_Evening_Survey_June_28_2024_22_02.csv",
              "Day_1_LVC_Evening_Survey_June_28_2024_22_54.csv"," Day_5_LVC_Afternoon_Survey_June_28_2024_23_03.csv",
              "Day_8_LVC_Evening_Survey_June_28_2024_23_10.csv","Day_1_LVC_Midday_Survey_June_28_2024_21_59.csv",
              "Day_5_LVC_Evening_Survey_June_28_2024_23_04.csv","Day_8_LVC_Midday_Survey_June_28_2024_23_10.csv",
              "Day_2_LVC_Afternoon_Survey_June_28_2024_22_56.csv","Day_5_LVC_Midday_Survey_June_28_2024_23_04.csv",
              "Day_9_LVC_Afternoon_Survey_June_28_2024_23_11.csv","Day_2_LVC_Evening_Survey_June_28_2024_22_57.csv",
              "Day_6_LVC_Afternoon_Survey_June_28_2024_23_05.csv","Day_9_LVC_Evening_Survey_June_28_2024_23_11.csv",
              "Day_2_LVC_Midday_Survey_June_28_2024_22_56.csv","Day_6_LVC_Evening_Survey_June_28_2024_23_05.csv",
              "Day_9_LVC_Midday_Survey_June_28_2024_23_12.csv","Day_3_LVC_Afternoon_Survey_June_28_2024_22_59.csv",
              "Day_6_LVC_Midday_Survey_June_28_2024_23_06.csv","Day_3_LVC_Evening_Survey_June_28_2024_22_59.csv",
              "Day_7_LVC_Afternoon_Survey_June_28_2024_23_07.csv")

# Define the file path
file_path <- 'C:/Users/timothy/OneDrive/Documents/temp/'

df_a <- read.csv(file = 'C:/Users/timothy/OneDrive/Documents/temp/')

"To ensure that you are paying attention"


# Read the CSV file
  data <- read.csv(full_path, header = FALSE)
  
  # Set the second row as the header
  names(data) <- data[2, ]
  
  # Remove the first and third rows
  data <- data[-c(1, 3), ]
  
  # Reset the row indices
  rownames(data) <- NULL

```

```{r}
library(dplyr)


# Reading the CSV files with specific column types
dataa <- read.csv(file = 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\Final_sample_0706.csv', stringsAsFactors = FALSE)
datab <- read.csv(file = 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\humi_nar_0706.csv', stringsAsFactors = FALSE)
datac <- read.csv(file = 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\IDs_with_yearly.csv', stringsAsFactors = FALSE)
# Performing a full join to keep all cases from both files
df <- full_join(dataa, datab, by = "CEO_ID")

# Writing the merged data to a CSV file
write.csv(df, "C:\\Users\\timothy\\OneDrive\\Documents\\temp\\joined_0706.csv", na = '', row.names = FALSE)

onlyinsample <- dataa %>%
  filter(!(CEO_ID %in% datac$CEO_ID))
onlyinperfor <- datac %>%
  filter(!(CEO_ID %in% dataa$CEO_ID))
write.csv(onlyinsample, "C:\\Users\\timothy\\OneDrive\\Documents\\temp\\onlyinsample.csv", na = '', row.names = FALSE)
write.csv(onlyinperfor, "C:\\Users\\timothy\\OneDrive\\Documents\\temp\\onlyinperfor.csv", na = '', row.names = FALSE)
rm(list=ls())
```

```{r}
# Load necessary libraries
library(dplyr)
library(readr)

# Load the long.csv and short.csv files
long_df <- read.csv('C:\\Users\\timothy\\OneDrive\\Documents\\temp\\long.csv', stringsAsFactors = FALSE)

short_df <- read.csv('C:\\Users\\timothy\\OneDrive\\Documents\\temp\\short.csv', stringsAsFactors = FALSE)

# Perform the filtering based on the combination of firmid, ceoid, and year
long_filtered_df <- long_df %>%
  inner_join(short_df %>% select(firmid, ceoid, year), by = c("firmid", "ceoid", "year"))

rm(long_df)
rm(short_df)

# Calculate roa-1 by arranging data by firmid and year, then using lag() function
long_filtered_df <- long_filtered_df %>%
  arrange(firmid, year) %>% 
  group_by(firmid) %>%
  mutate(roa_minus_1 = lag(roa, order_by = year))

# Load the more4longs.csv file
more4longs_df <- read.csv('C:\\Users\\timothy\\OneDrive\\Documents\\temp\\more4longs.csv', stringsAsFactors = FALSE)

# Merge the board_director_women_percentage from more4longs.csv into long_filtered_df
long_filtered_df <- long_filtered_df %>%
  left_join(more4longs_df %>% select(firmid, ceoid, year, board_director_women_percentage), 
            by = c("firmid", "ceoid", "year"))

# Merge the prior_year__ROA from more4longs.csv into long_filtered_df
long_filtered_df <- long_filtered_df %>%
  left_join(more4longs_df %>% select(firmid, ceoid, year, prior_year__ROA), 
            by = c("firmid", "ceoid", "year"))

# Fill missing values of roa_minus_1 with prior_year__ROA based on the same firmid, ceoid, year
long_filtered_df <- long_filtered_df %>%
  mutate(roa_minus_1 = ifelse(is.na(roa_minus_1), prior_year__ROA, roa_minus_1))

# Drop the prior_year__ROA column as it is no longer needed
long_filtered_df <- long_filtered_df %>% select(-prior_year__ROA)

rm(more4longs_df)

# Save the updated dataframe to a new CSV file
write.csv(long_filtered_df, 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\long_filtered_with_roa_minus.csv', row.names = FALSE)

rm(list=ls())
```

```{r}
# Load necessary libraries
library(dplyr)

# Define file paths
sic_file <- 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\SIC.csv'
ceo_demographics_file <- 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\CEO_demographics.csv'
output_file <- 'C:\\Users\\timothy\\OneDrive\\Documents\\temp\\CEO_demographics_updated.csv'

# Read the SIC and CEO_demographics datasets
SIC <- read.csv(sic_file)
CEO_demographics <- read.csv(ceo_demographics_file)

# Inspect the first few rows of each dataframe (optional)
# head(SIC)
# head(CEO_demographics)

# Merge the datasets based on the 'company' column
CEO_demographics_updated <- CEO_demographics %>%
  left_join(SIC %>% select(company, SIC), by = "company")

# Save the updated dataset to a new CSV file without writing NA values
write.csv(CEO_demographics_updated, output_file, row.names = FALSE, na = "")

rm(list=ls())
```

```{r}
# Load required library
library(dplyr)

# Read the CSV files
jap_sample <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_01.csv")
distance <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/distance.csv")

# Select only the required columns from the distance dataset
distance_subset <- distance %>% 
  select(firmid, distance_to_metropolitan_in_kilometers)

# Merge the datasets based on firmid, only adding the desired column
merged_data <- left_join(jap_sample, distance_subset, by = "firmid")

# Write the merged dataset to a new CSV file
write.csv(merged_data, "C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_01_with_distance.csv", row.names = FALSE)

rm(list=ls())
```

```{r}
# Load required library
library(dplyr)

# Read the CSV files
JAP_sample_00_updated_04262023 <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_00_updated_04262023.csv",na.strings = "")
JAP_CEO <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/JAP_CEO.csv",na.strings = "")

# Select only the required columns from the distance dataset
JAP_CEO_subset <- JAP_CEO %>% 
  select(ceoid, CEO_birthcountry, country_headquater, difference_code)

# Merge the datasets based on firmid, only adding the desired column
merged_data <- left_join(JAP_sample_00_updated_04262023, JAP_CEO_subset, by = "ceoid")

# Write the merged dataset to a new CSV file
write.csv(merged_data, "C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_00_updated_04262023_with_birthinfo.csv", row.names = FALSE, na = "")

rm(list=ls())
```

```{r}
# Load necessary libraries
library(dplyr)

# Load the long.csv and short.xlsx files
short_df <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_01_with_distance.csv", na.strings = "")
long_df <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_00_updated_04262023_with_birthinfo.csv", na.strings = "")

# Perform the filtering based on the combination of firmid, ceoid, and year
long_filtered_df <- long_df %>%
  inner_join(short_df %>% select(firmid, ceoid, year), by = c("firmid", "ceoid", "year"))

# Save the result to a new CSV file
write.csv(long_filtered_df, "C:/Users/timothy/OneDrive/Documents/temp/JAP_sample_00_updated_04262023_with_birthinfo_short.csv", row.names = FALSE, na = "")
rm(list=ls())
```

```{r}
# Load the necessary package
library(dplyr)

# Read the CSV files
df_2530 <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/MGT_2530.csv", na.strings = "")
df_5560 <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/MGT_5560.csv", na.strings = "")
df_CF <- read.csv("C:/Users/timothy/OneDrive/Documents/temp/Career_Fair.csv", na.strings = "")

# Check for cases where T_ID is present in both files
common_cases_2530 <- inner_join(df_2530, df_CF, by = "T_ID")

# Save the result to a new CSV file
write.csv(common_cases_2530, "C:/Users/timothy/OneDrive/Documents/temp/common_cases_2530.csv", row.names = FALSE, na = "")

# Check for cases where T_ID is present in both files
common_cases_2530 <- inner_join(df_2530, df_CF, by = "T_ID")
common_cases_5560 <- inner_join(df_5560, df_CF, by = "T_ID")
# Save the result to a new CSV file
write.csv(common_cases_5560, "C:/Users/timothy/OneDrive/Documents/temp/common_cases_5560.csv", row.names = FALSE, na = "")
rm(list=ls())
```

```{r}
# add industry values for cases
# Load necessary libraries
library(dplyr)
library(tidyr)
library(readr)

# Define the file path
file_path <- "C:/Users/timothy/OneDrive/Documents/temp/ForbesGlobal_2018_2024.csv"

# Load the CSV file
df <- read_csv(file_path)

# Fill missing Industry values based on existing values for the same Company
# Leave it empty if no value is found
df_filled <- df %>%
  group_by(Company) %>%
  mutate(Industry = ifelse(is.na(Industry), first(na.omit(Industry)), Industry)) %>%
  ungroup() %>%
  mutate(Industry = ifelse(is.na(Industry), "", Industry))  # Replace remaining NAs with empty strings

# View the updated dataframe
print(df_filled)

# Save the updated dataframe to a new CSV file
write_csv(df_filled, "C:/Users/timothy/OneDrive/Documents/temp/ForbesGlobal_2018_2024_filled.csv")

```

```{r}
# check only in B

# Set file paths
new_company_file <- "C:/Users/timothy/OneDrive/Documents/temp/New_nonUSA_company.csv"
old_company_file <- "C:/Users/timothy/OneDrive/Documents/temp/Old_nonUSA_company.csv"
# Load the readr package
library(readr)

# Use readr's read_csv to load the files with better encoding handling
new_company <- read_csv(new_company_file)
old_company <- read_csv(old_company_file)

# Convert the 'Company' columns to UTF-8 encoding to handle special characters
new_company$Company <- iconv(new_company$Company, from = "latin1", to = "UTF-8", sub = "") 
old_company$Company <- iconv(old_company$Company, from = "latin1", to = "UTF-8", sub = "") 

# Check for any remaining problematic characters (optional, for inspection)
new_company$Company[is.na(new_company$Company)]
old_company$Company[is.na(old_company$Company)]

# Convert 'Company' columns to lowercase for case-insensitive comparison
new_company$Company_lower <- tolower(new_company$Company)
old_company$Company_lower <- tolower(old_company$Company)

# Add the new variable 'Only_New' to 'New_USA_company' (case-insensitive comparison)
new_company$Only_New <- ifelse(new_company$Company_lower %in% old_company$Company_lower, "N", "Y")

# Remove the temporary 'Company_lower' column
new_company$Company_lower <- NULL

# Save the updated 'New_USA_company' with the new variable
write_csv(new_company, "C:/Users/timothy/OneDrive/Documents/temp/New_nonUSA_company_updated.csv")
rm(list=ls())
```

